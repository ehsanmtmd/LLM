{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T06:45:40.403033Z",
     "start_time": "2025-01-29T06:45:40.396487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ],
   "id": "aef184a5642bf495",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T07:10:22.777105Z",
     "start_time": "2025-01-29T07:04:40.361160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ollama import chat, embeddings\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 1. Extract and preprocess content from URL\n",
    "def extract_content_from_url(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        content = soup.get_text()  # Extract plain text from the HTML\n",
    "        return content\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching URL {url}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "# 4. Context retrieval system\n",
    "def find_relevant_chunks(query, top_k=3):\n",
    "    # Generate query embedding\n",
    "    query_embed = embeddings(model='gemma2:9b', prompt=query)['embedding']\n",
    "\n",
    "    # Calculate similarities\n",
    "    scores = cosine_similarity([query_embed], chunk_embeddings)[0]\n",
    "\n",
    "    # Return top chunks\n",
    "    best_indices = np.argsort(scores)[-top_k:][::-1]\n",
    "    return \"\\n---\\n\".join([chunks[i] for i in best_indices])\n",
    "\n",
    "# 5. RAG-enhanced chat function\n",
    "def rag_chat(query):\n",
    "    # Retrieve context\n",
    "    context = find_relevant_chunks(query)\n",
    "\n",
    "    # Create augmented prompt\n",
    "    prompt = f\"\"\"Answer the question using this context:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "Answer comprehensive in Persian:\"\"\"\n",
    "\n",
    "    # Get response\n",
    "    response = chat(model='gemma2:9b', messages=[\n",
    "        {'role': 'user', 'content': prompt}\n",
    "    ])\n",
    "\n",
    "    return response['message']['content']\n",
    "\n",
    "# Example usage\n",
    "from datetime import datetime\n",
    "start = datetime.now()\n",
    "# Replace with the desired URL(s)\n",
    "urls = [\n",
    "    \"https://ensani.ir/fa/article/83978/%D8%AE%D9%84%DB%8C%D9%81%D9%87-%D8%B3%D9%84%D8%B7%D8%A7%D9%86-%D8%B3%D9%84%D8%B7%D8%A7%D9%86-%D8%A7%D9%84%D8%B9%D9%84%D9%85%D8%A7-%D9%81%D9%82%DB%8C%D9%87-%D9%88-%D9%88%D8%B2%DB%8C%D8%B1-%D8%A7%D8%B9%D8%B8%D9%85-%D8%B9%D8%B5%D8%B1-%D8%B5%D9%81%D9%88%D9%89\",\n",
    "    \"https://article.bsfe.ir/ArticleShow.aspx?rs=326\"\n",
    "]\n",
    "\n",
    "# Aggregate content from URLs\n",
    "text = \"\"\n",
    "for url in urls:\n",
    "    text += extract_content_from_url(url) + \"\\n\"\n",
    "\n",
    "# 2. Split with overlap\n",
    "chunk_size = 1000\n",
    "overlap = 200\n",
    "chunks = [text[i:i + chunk_size] for i in range(0, len(text), chunk_size - overlap)]\n",
    "\n",
    "# 3. Create embeddings using dorna-llama3\n",
    "chunk_embeddings = []\n",
    "for chunk in chunks:\n",
    "    response = embeddings(model='gemma2:9b', prompt=chunk)\n",
    "    chunk_embeddings.append(response['embedding'])\n",
    "\n",
    "duration_text_extractor  = datetime.now() - start\n",
    "# Format timedelta without microseconds\n",
    "hours, remainder = divmod(duration_text_extractor.total_seconds(), 3600)\n",
    "minutes, seconds = divmod(remainder, 60)\n",
    "formatted_duration_text_extractor = f\"{int(hours):02}:{int(minutes):02}:{int(seconds):02}\"\n",
    "print('process url_crowling: ',formatted_duration_text_extractor)  # Output: 00:35:51\n",
    "\n",
    "response = rag_chat(\"خلیفه سلطان که بود و چه کرد؟\")\n",
    "\n",
    "duration  = datetime.now() - start\n",
    "# Format timedelta without microseconds\n",
    "hours, remainder = divmod(duration.total_seconds(), 3600)\n",
    "minutes, seconds = divmod(remainder, 60)\n",
    "formatted_duration = f\"{int(hours):02}:{int(minutes):02}:{int(seconds):02}\"\n",
    "print('Total process time: ',formatted_duration)  # Output: 00:35:51\n",
    "\n",
    "file_path = r'C:\\\\Users\\\\User\\\\Desktop\\\\LLM\\\\Test_LLM_fun-tuning\\\\output_url1_2_Gemma2.txt'\n",
    "with open(file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(response + '\\n\\n')\n",
    "print(f\"Responses saved to {file_path}\")\n",
    "print(\"پاسخ:\", response)\n"
   ],
   "id": "41ab26e3f2c1463a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process text_extractor:  00:02:42\n",
      "Total process time:  00:05:42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1216"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Responses saved to C:\\\\Users\\\\User\\\\Desktop\\\\LLM\\\\Test_LLM_fun-tuning\\\\output_url1_2_Gemma2.txt\n",
      "پاسخ: خلیفه سلطان، لقب  **ابو القاسم خلیفه بن احمد حبیب الله** معروف به **سلطان العلماء**، فقیه، عالم، و وزیر اعظم در زمان حکومت صفوی بود. او در قرن دهم هجری قمری (قرن شانزدهم میلادی) زندگی می‌کرد و از شخصیت‌های برجسته دوره صفویه به‌شمار می‌رفت.\n",
      "\n",
      "خلیفه سلطان به خاطر دانش فراوانش در علوم اسلامی، به‌خصوص فقه، مورد احترام و تکریم بزرگان زمان خود قرار داشت. او فقیهی برجسته بود و در حوزه‌های مختلف علمی تبحر داشته است. \n",
      "\n",
      "از جمله مهم‌ترین خدمات خلیفه سلطان می‌توان به:\n",
      "\n",
      "\n",
      "* **وزارت اعظم:** \n",
      "خلیفه سلطان در دوران حکمرانی شاه اسماعیل صفوی، وزیر اعظم شد و نقش بسزایی در اداره امور مملکت ایفا کرد. او با درایت و تدبیر خود توانست از  بلند شدن نام حکومت صفویه یاری کند.\n",
      "\n",
      "\n",
      "* **تأثیر بر سیاست:** \n",
      "خلیفه سلطان به دلیل دانش و تجربیاتش، در سیاست گذاری صفویان نیز نقشی اساسی داشت. نظراتش در زمینه‌های مختلف، مورد توجه شاه اسماعیل قرار می‌گرفت و گاه، تصمیمات مهم با تأثیر او گرفته می‌شد.\n",
      "\n",
      "* **تألیف کتاب‌ها:**\n",
      "خلیفه سلطان علاوه بر وزارت، به نگارش کتب فقهی و تفسیر قرآن نیز اشتغال داشت. برخی از آثار او که هنوز هم مورد استفاده قرار می‌گیرند، شامل:\n",
      "\n",
      "\n",
      "    *   **التحفة السنیّة:** در شرح احکام نماز\n",
      "    *   **هدایة العلماء:**  در شرح مکارم اخلاقی \n",
      "\n",
      "خلیفه سلطان  فردی دانشمند و سیاستمدار توانمند بود که در تاریخ صفویه، جایگاه ویژه ای داشت.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6efbf182a5288fa6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
